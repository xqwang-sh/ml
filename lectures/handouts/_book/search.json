[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "数据挖掘与机器学习课程讲义",
    "section": "",
    "text": "本讲义将系统地介绍机器学习的基本概念、主要模型以及实践应用。\n引言:\n机器学习是人工智能的一个重要分支，它是指从数据中自动学习规律和模式，并利用这些规律和模式进行预测和决策的过程。机器学习在量化投资、金融科技等领域有广泛应用。由于课程时间有限，本讲义将重点介绍机器学习中的监督学习与无监督学习，以及其在金融预测中的应用。\n课程内容:\n\n机器学习基础\n金融数据获取与数据分析基础\n监督学习（上）\n监督学习（下）\n模型评估与优化\n\n课程项目:\n\n借贷违约风险评估\n\n使用说明:\n\n本讲义使用 Quarto 创建，可以方便地生成 HTML, PDF, ePub 等多种格式。\n点击左侧导航栏可以浏览不同章节的内容。\n\n希望本讲义能帮助您更好地学习和理解机器学习！",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "01_ml_basic.html",
    "href": "01_ml_basic.html",
    "title": "2  机器学习基础",
    "section": "",
    "text": "2.1 机器学习简介",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>机器学习基础</span>"
    ]
  },
  {
    "objectID": "01_ml_basic.html#机器学习简介",
    "href": "01_ml_basic.html#机器学习简介",
    "title": "2  机器学习基础",
    "section": "",
    "text": "2.1.1 什么是机器学习？\n机器学习是人工智能领域中一个非常热门且快速发展的分支。简单来说，机器学习就是让计算机通过学习数据，而不是依赖明确的编程指令，来完成特定的任务或解决问题。想象一下，我们教小孩子认识猫和狗，不是告诉他们猫和狗的具体特征（比如多少根胡须，耳朵的形状），而是给他们看大量的猫和狗的图片，告诉他们哪些是猫，哪些是狗。通过不断学习，孩子就能自己总结出猫和狗的区别，并且能够识别新的猫和狗。机器学习的原理与之类似，它使用算法来解析数据，从中学习，然后利用学到的知识对新数据做出预测或决策。\n\n\n2.1.2 机器学习的主要特点\n\n数据驱动: 机器学习模型的核心是数据。模型从数据中学习规律，数据越多、质量越高，模型通常就越强大。\n自动学习: 机器学习系统能够自动地从数据中发现模式和规律，无需人工明确指定规则。\n持续优化: 机器学习模型可以通过不断学习新的数据来提升性能，使其能够适应变化的环境。\n泛化能力: 训练好的模型不仅能处理训练数据，还能对未见过的新数据进行预测或决策。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>机器学习基础</span>"
    ]
  },
  {
    "objectID": "01_ml_basic.html#机器学习的主要类型",
    "href": "01_ml_basic.html#机器学习的主要类型",
    "title": "2  机器学习基础",
    "section": "2.2 机器学习的主要类型",
    "text": "2.2 机器学习的主要类型\n\n2.2.1 监督学习 (Supervised Learning)\n监督学习就像是有一位老师（监督者）指导计算机学习。我们提供给计算机带有”标签”的数据，标签就是我们希望模型预测的答案。例如，如果我们想让模型识别图片中的水果是苹果还是香蕉，我们就需要提供大量已经标记好（苹果或香蕉）的水果图片给模型学习。模型学习的目标就是找到输入数据（水果图片）和输出标签（苹果或香蕉）之间的关系。\n主要特点:\n\n需要使用带有标签的数据进行训练。\n目标是学习输入特征与输出标签之间的映射关系。\n主要解决分类和回归问题。分类问题是预测数据属于哪个类别（例如，垃圾邮件检测），回归问题是预测一个连续的数值（例如，房价预测）。\n\n现实生活案例:\n\n垃圾邮件检测: 通过分析邮件的内容（关键词、发件人等）来判断邮件是否为垃圾邮件。\n图像识别: 识别图片中的物体，例如人脸识别、交通标志识别等。\n语音识别: 将语音转换成文字。\n\n金融领域应用示例:\n\n信用评分: 根据用户的个人信息和交易记录预测其信用等级。\n股票价格预测: 预测股票未来价格的涨跌趋势。\n客户流失预测: 预测哪些客户可能在未来一段时间内停止使用某项金融服务。\n\n\n\n2.2.2 无监督学习 (Unsupervised Learning)\n无监督学习则像是让计算机在没有老师指导的情况下，自己去探索数据的内在结构和模式。我们提供给计算机的数据没有标签，模型需要自己去发现数据中的隐藏信息。例如，给计算机一大堆新闻报道，让它自己将这些新闻按照主题进行分类，这就是一个无监督学习的任务。\n主要特点:\n\n使用没有标签的数据进行学习。\n目标是发现数据中的内在结构、模式或关系。\n常用于聚类、降维和关联规则挖掘等任务。聚类是将相似的数据点 grouping 在一起，降维是在保留数据主要信息的同时减少数据的维度，关联规则挖掘是发现数据中不同项之间的关联关系。\n\n现实生活案例:\n\n客户分群: 根据用户的购买行为将用户分成不同的群体，以便进行个性化营销。\n社交网络分析: 分析社交网络中用户之间的关系，发现社区结构或影响力中心。\n异常检测: 在大量数据中找出异常或不正常的点，例如信用卡欺诈检测。\n\n金融领域应用示例:\n\n投资组合风险分析: 通过聚类分析将不同的投资资产进行分类，评估投资组合的风险。\n市场细分: 将市场上的客户按照不同的特征进行细分，以便更好地了解市场需求。\n交易异常检测: 检测金融市场中不正常的交易行为，例如内幕交易或市场操纵。\n\n\n\n2.2.3 强化学习 (Reinforcement Learning)\n强化学习更像是训练一只宠物。我们不直接告诉宠物应该做什么，而是通过奖励或惩罚来引导它学习。计算机作为一个”智能体”，在与环境的交互中不断尝试不同的动作。如果某个动作让它达到了目标（例如，在游戏中获得高分，或者在交易中获得盈利），我们就给予奖励；如果动作不好，就给予惩罚。通过不断地试错和学习，智能体最终学会如何在特定环境中做出最优的决策，以获得最大的累积奖励。\n主要特点:\n\n通过与环境的交互进行学习。\n通过奖励和惩罚来指导学习方向。\n目标是学习在特定环境中采取最优的行动策略，以最大化累积奖励。\n适合解决序贯决策问题，即一系列连续决策的问题。\n\n现实生活案例:\n\n游戏AI: 训练AI玩游戏，例如围棋、象棋、电子游戏等。\n机器人控制: 训练机器人完成各种任务，例如自动驾驶、物体抓取等。\n推荐系统优化: 通过用户与推荐系统的交互（点击、购买等）来优化推荐策略。\n\n金融领域应用示例:\n\n自动化交易: 开发自动交易程序，根据市场情况自动进行买卖操作。\n投资组合管理: 动态调整投资组合，以最大化收益并控制风险。\n订单执行优化: 优化股票交易的订单执行策略，以降低交易成本。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>机器学习基础</span>"
    ]
  },
  {
    "objectID": "01_ml_basic.html#机器学习项目流程",
    "href": "01_ml_basic.html#机器学习项目流程",
    "title": "2  机器学习基础",
    "section": "2.3 机器学习项目流程",
    "text": "2.3 机器学习项目流程\n一个完整的机器学习项目通常包含以下几个关键步骤：\n\n数据收集与预处理:\n\n数据获取: 收集项目所需的数据。数据来源可能包括数据库、文件、网络爬虫、传感器等等。\n数据清洗: 处理数据中的缺失值、异常值、重复值和错误数据，确保数据质量。\n特征工程: 从原始数据中提取有用的特征，或者创建新的特征，以便模型更好地学习。特征工程是机器学习项目中非常重要的一步，好的特征能够显著提升模型性能。\n\n模型选择与训练:\n\n选择合适的算法: 根据问题的类型（分类、回归、聚类等）和数据的特点，选择合适的机器学习算法。例如，对于分类问题可以选择逻辑回归、支持向量机、决策树、随机森林等算法。\n划分数据集: 将数据集划分为训练集、验证集和测试集。训练集用于训练模型，验证集用于调整模型参数，测试集用于评估模型的泛化能力。\n模型训练与调参: 使用训练集数据训练模型，并使用验证集调整模型参数，例如超参数优化。目标是找到在验证集上表现最好的模型参数。\n\n模型评估与优化:\n\n性能评估: 使用测试集评估模型的性能。根据问题的类型选择合适的评估指标，例如准确率、精确率、召回率、F1 值（分类问题），均方误差、平均绝对误差（回归问题）等。\n模型调优: 如果模型性能不理想，需要进一步分析原因，并进行模型调优。调优方法可能包括：调整模型参数、尝试不同的算法、改进特征工程、增加数据量等。\n结果分析: 分析模型的预测结果，理解模型的优点和不足，为后续的模型改进提供方向。\n\n模型部署与监控:\n\n模型部署: 将训练好的模型部署到实际应用环境中。部署方式可能包括将模型集成到应用程序中、部署为 Web 服务等。\n性能监控: 在模型上线运行后，需要持续监控模型的性能。因为实际应用环境中的数据分布可能会发生变化（即”概念漂移”），导致模型性能下降。\n定期更新: 根据监控结果，定期使用新的数据重新训练模型，或者调整模型参数，以保持模型的性能和适应性。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>机器学习基础</span>"
    ]
  },
  {
    "objectID": "01_ml_basic.html#总结",
    "href": "01_ml_basic.html#总结",
    "title": "2  机器学习基础",
    "section": "2.4 总结",
    "text": "2.4 总结\n\n机器学习是一种强大的数据分析和预测工具，能够从数据中自动学习模式和规律。\n监督学习、无监督学习和强化学习是机器学习的三种主要类型，它们适用于不同的问题场景。\n机器学习在金融领域有着广泛的应用前景，可以用于风险管理、投资决策、客户服务等多个方面。\n成功应用机器学习需要一个完整的项目流程，包括数据准备、模型构建、评估优化和部署监控等环节。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>机器学习基础</span>"
    ]
  },
  {
    "objectID": "lab02_data.html",
    "href": "lab02_data.html",
    "title": "3  金融数据获取与数据分析基础",
    "section": "",
    "text": "3.1 内容概要",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>金融数据获取与数据分析基础</span>"
    ]
  },
  {
    "objectID": "lab02_data.html#内容概要",
    "href": "lab02_data.html#内容概要",
    "title": "3  金融数据获取与数据分析基础",
    "section": "",
    "text": "金融数据获取\n\n股票、债券、期货市场数据\n数据接口 (Tushare, Yahoo Finance)\n上市公司财务报表数据\n金融文本数据\n\nPython数据分析基础\n\nNumPy, Pandas 常用功能\n数据预处理与清洗\n探索性数据分析 (EDA)\n\nAI辅助编程实践\n\n代码生成、解释、优化\n最佳实践案例",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>金融数据获取与数据分析基础</span>"
    ]
  },
  {
    "objectID": "lab02_data.html#金融数据获取",
    "href": "lab02_data.html#金融数据获取",
    "title": "3  金融数据获取与数据分析基础",
    "section": "3.2 金融数据获取",
    "text": "3.2 金融数据获取\n\n3.2.1 股票市场数据\n\n数据类型：\n\n基本行情数据：股票代码、名称、交易所、行业\n交易数据：开盘价、收盘价、最高价、最低价、成交量、成交额\n财务数据：资产负债表、利润表、现金流量表、财务指标 (ROE, EPS, PE)\n股东信息：股东户数、十大股东\n分红送股：分红金额、送股比例\n\n常用数据源：\n\nTushare (tushare.pro): 国内股票数据接口，数据全面，API友好 (稍后详细介绍)\nYahoo Finance (finance.yahoo.com): 全球股票数据，免费API (yfinance Python库)\n交易所官方API: 上海证券交易所 (sse.com.cn), 深圳证券交易所 (szse.cn) - 数据权威，但API可能较为复杂\n券商API: 部分券商提供API接口，方便交易和数据获取 (例如：同花顺, 东方财富)\nWind (wind.com.cn), Bloomberg (bloomberg.com): 专业金融数据服务商，数据质量高，但价格昂贵 (机构常用)\n\n\n\n\n3.2.2 债券市场数据\n\n数据类型：\n\n债券基本信息：债券代码、名称、发行人、债券类型、票面利率、到期日\n债券交易数据：成交价、收益率、成交量\n债券估值数据：中债估值、市场估值\n债券评级：评级机构、评级结果\n债券发行数据：发行规模、发行利率\n\n常用数据源：\n\nWind (wind.com.cn), Bloomberg (bloomberg.com): 专业金融数据服务商\n中债网 (chinabond.com.cn): 中国债券信息网，官方数据\n交易所债券信息平台: 上海证券交易所债券信息平台, 深圳证券交易所债券信息平台\n券商研究报告: 部分券商研报会提供债券市场数据和分析\n\n\n\n\n3.2.3 期货市场数据\n\n数据类型：\n\n期货合约信息：合约代码、标的资产、交易单位、最小变动价位、交割月份\n期货交易数据：开盘价、收盘价、最高价、最低价、成交量、持仓量\n期货指数数据：商品期货指数、股指期货指数\n期货仓单数据：仓单数量、注册仓单、有效预报\n期货持仓排名：期货交易所公布的持仓排名数据\n\n常用数据源：\n\nCTP接口: 期货公司提供的交易接口，可以获取实时行情和历史数据 (专业交易者常用)\n同花顺, 文华财经: 金融软件，提供期货行情和数据\n期货交易所网站: 各期货交易所 (例如：上海期货交易所, 大连商品交易所, 郑州商品交易所) 网站通常提供数据下载\nWind (wind.com.cn), Bloomberg (bloomberg.com): 专业金融数据服务商\n\n\n\n\n3.2.4 数据接口使用：Tushare\n\nTushare Pro (tushare.pro): 注册认证后可获取更丰富的数据和更高的API访问权限 (收费)\n安装: pip install tushare\n初始化: 需要token (注册Tushare Pro后获取)\nimport tushare as ts\n\n# 初始化 pro 接口\npro = ts.pro_api('YOUR_TOKEN') # 替换为你的token\n常用API示例：\n\n获取股票列表: pro.stock_basic()\n获取股票日线行情: ts.get_k_data('600519', start='2023-01-01', end='2023-01-31') (旧接口) 或 pro.daily(ts_code='600519.SH', start_date='20230101', end_date='20230131') (Pro接口)\n获取公司财务报表: pro.fina_indicator(ts_code='600519.SH', period='20221231')\n更多API: 参考 Tushare 官方文档 (https://tushare.pro/document/2)\n\n注意事项:\n\nAPI访问频率限制: 免费用户有访问频率限制，避免频繁调用\n数据权限: 不同级别用户权限不同，部分数据需要Pro会员\n数据质量: 注意核对数据质量，不同接口数据可能存在差异\n\n\n\n\n3.2.5 数据接口使用：Yahoo Finance\n\nyfinance 库主要用于获取海外股票数据，国内A股数据质量可能不如 Tushare 等国内接口，因此本课程示例主要使用 Tushare 获取A股数据。 Yahoo Finance 示例如下，如果需要分析海外股票，可以使用 yfinance。\nimport yfinance as yf\n\n# 下载 苹果 (AAPL) 股票数据\naapl = yf.Ticker(\"AAPL\")\n\n# 获取历史数据\nhist = aapl.history(period=\"5y\") # 5年历史数据\nprint(hist.head())\n\n# 获取公司信息\ninfo = aapl.info\nprint(info)\n\n# 获取分红信息\ndividends = aapl.dividends\nprint(dividends)\n\n# 更多功能参考 yfinance 文档\n优点: 免费，全球股票数据，使用简单 (如果分析海外股票)\n缺点: A 股数据质量可能不如国内专业数据源，API 稳定性可能不如官方接口，文档相对简单，A 股代码可能需要调整\n\n\n\n3.2.6 上市公司财务报表数据\n\n数据类型:\n\n资产负债表: 反映公司在特定时点的资产、负债和所有者权益状况\n利润表: 反映公司在特定期间的经营成果 (收入、成本、利润)\n现金流量表: 反映公司在特定期间的现金流入和流出\n财务指标: 根据财务报表计算的各种指标，例如：盈利能力指标 (ROE, ROA, 净利润率), 偿债能力指标 (资产负债率, 流动比率), 运营能力指标 (存货周转率, 应收账款周转率), 成长能力指标 (营业收入增长率, 净利润增长率)\n\n数据来源:\n\nCSMAR (csmar.com): 国泰安，国内权威的金融数据库，数据质量高，但收费，高校和研究机构常用\nCNRDS (cnrds.com): 中国研究数据服务平台，国内较全面的研究数据平台，数据覆盖范围广，部分数据收费，学术研究常用\nWind (wind.com.cn): 专业金融数据服务商，提供全面的财务报表和财务指标数据，收费昂贵，金融机构常用\n巨潮资讯网 (cninfo.com.cn): 免费的上市公司公告平台，包含上市公司定期报告 (年报、季报)，可以从中获取财务报表数据，但需要自行解析和整理",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>金融数据获取与数据分析基础</span>"
    ]
  },
  {
    "objectID": "lab02_data.html#python数据分析基础",
    "href": "lab02_data.html#python数据分析基础",
    "title": "3  金融数据获取与数据分析基础",
    "section": "3.3 Python数据分析基础",
    "text": "3.3 Python数据分析基础\n\n3.3.1 NumPy 基础\n\nNumPy: 基于Python的科学计算库，提供高效的多维数组对象和工具，用于数据分析和科学计算\n核心功能:\n\n数组操作: 创建、操作、转换数组\n数学运算: 线性代数、傅里叶变换、随机数生成\n数据IO: 读取和写入各种数据格式 (CSV, Excel, SQL, JSON, HTML)\n\n常用操作:\nimport numpy as np\nimport pandas as pd\n\n# 假设您已下载 茅台 (600519.SH) 近5日收盘价数据到 moutai_daily.csv\n# CSV 文件包含 Date 和 Close 列\nmoutai_daily_df = pd.read_csv('moutai_daily.csv')\nclose_prices = moutai_daily_df['Close'].values\n\n# 计算平均收盘价\navg_price = np.mean(close_prices)\nprint(f\"平均收盘价: {avg_price:.2f}\")\n\n# 计算收盘价的标准差\nstd_price = np.std(close_prices)\nprint(f\"收盘价标准差: {std_price:.2f}\")\n\n# 计算每日涨跌幅 (假设前一日收盘价在 CSV 中也存在)\nprevious_close_prices = moutai_daily_df['Close'].shift(1).fillna(method='bfill').values #  向前填充第一个缺失值\nprice_change_ratio = (close_prices[1:] - previous_close_prices[1:]) / previous_close_prices[1:]\nprint(f\"每日涨跌幅: {price_change_ratio}\")\n\n\n\n3.3.2 2.2 Pandas 基础\n\nPandas (Panel Data): 基于NumPy的数据分析库，提供 Series (一维带标签数组) 和 DataFrame (二维表格型数据) 数据结构\n核心功能:\n\n数据结构: Series 和 DataFrame，方便数据表示和操作\n数据清洗: 处理缺失值、重复值、异常值\n数据预处理: 数据转换、数据标准化、特征工程\n数据分析: 数据选择、过滤、排序、分组聚合、透视表\n数据IO: 读取和写入各种数据格式 (CSV, Excel, SQL, JSON, HTML)\n\n实践示例: 茅台股票数据分析:\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tushare as ts\n\n# 设置Tushare token\nts.set_token('你的token')\npro = ts.pro_api()\n\n# 获取茅台股票数据（最近60个交易日）\ndf = pro.daily(ts_code='600519.SH', \n              start_date='20240101',\n              end_date='20240331')\n\n# 基础数据处理\ndf['trade_date'] = pd.to_datetime(df['trade_date'])  # 转换日期格式\ndf = df.sort_values('trade_date')  # 按日期排序\n\n# 计算基本指标\ndf['daily_return'] = df['close'].pct_change()  # 日收益率\ndf['MA5'] = df['close'].rolling(window=5).mean()  # 5日均线\ndf['MA20'] = df['close'].rolling(window=20).mean()  # 20日均线\ndf['volatility'] = df['daily_return'].rolling(window=20).std() * np.sqrt(252)  # 20日年化波动率\n\n# 数据分析示例\nprint(\"\\n基本统计信息:\")\nprint(df[['close', 'daily_return', 'volatility']].describe())\n\nprint(\"\\n交易量最大的5天:\")\nprint(df.nlargest(5, 'vol')[['trade_date', 'close', 'vol']])\n\n# 计算每周平均收盘价和成交量\nweekly_stats = df.set_index('trade_date').resample('W').agg({\n    'close': 'mean',\n    'vol': 'sum'\n})\nprint(\"\\n每周统计:\")\nprint(weekly_stats.head())\n\n# 可视化分析\nplt.figure(figsize=(15, 10))\n\n# 绘制K线图和均线\nplt.subplot(2, 1, 1)\nplt.plot(df['trade_date'], df['close'], label='收盘价')\nplt.plot(df['trade_date'], df['MA5'], label='5日均线')\nplt.plot(df['trade_date'], df['MA20'], label='20日均线')\nplt.title('贵州茅台股价走势')\nplt.legend()\nplt.grid(True)\n\n# 绘制成交量和波动率\nplt.subplot(2, 1, 2)\nplt.bar(df['trade_date'], df['vol'], alpha=0.5, label='成交量')\nplt.plot(df['trade_date'], df['volatility'] * 1000000, 'r', label='波动率(放大1000000倍)')\nplt.title('成交量和波动率')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n练习建议:\n\n尝试修改上述代码，计算不同时间窗口的均线（如10日、30日均线）\n添加其他技术指标的计算（如RSI、MACD）\n尝试对比茅台与其他白酒股的表现\n探索不同的可视化方式（如蜡烛图）\n\n\n\n\n3.3.3 数据预处理与清洗\n\n数据质量问题:\n\n缺失值 (Missing Values): 数据记录中某些字段为空 (例如：股票停牌日可能成交量为缺失值)\n异常值 (Outliers): 与其他数据明显偏离的值 (例如：交易数据中的错误记录)\n重复值 (Duplicates): 重复的数据记录\n数据不一致 (Inconsistent Data): 同一信息在不同数据源中表示不一致\n数据类型错误 (Data Type Errors): 例如：数值型字段存储为字符串\n\n数据预处理步骤:\n\n数据清洗 (Data Cleaning): 处理缺失值、异常值、重复值、数据不一致等\n数据转换 (Data Transformation): 数据类型转换、数据格式转换、数据编码 (例如：One-Hot Encoding)\n数据标准化/归一化 (Data Scaling/Normalization): 将数据缩放到特定范围，消除量纲影响 (例如：Min-Max Scaling, Standardization)\n特征选择/特征构建 (Feature Selection/Feature Engineering): 选择重要特征，构建新特征 (后续章节详细介绍)\n\n\n\n\n3.3.4 探索性数据分析 (EDA)\n\n目的: 初步了解数据特征、发现数据规律、为后续建模提供方向\n常用方法:\n\n描述性统计: 均值、中位数、标准差、分位数、最大值、最小值等，了解数据分布和集中趋势 (例如：分析股票收盘价的统计特征)\n数据可视化: 直方图、箱线图、散点图、折线图、热力图等，直观展示数据分布、关系和异常 (例如：绘制股票价格走势图、成交量直方图)\n相关性分析: 计算特征之间的相关性，了解特征之间的关系 (例如：分析股票收益率与成交量之间的相关性)\n分组分析: 按类别分组，比较不同组别的数据特征差异 (例如：按行业分组，比较不同行业股票的盈利能力)\n\n常用可视化工具:\n\nMatplotlib: Python 基础绘图库，功能强大，定制性强\nSeaborn: 基于Matplotlib的高级可视化库，更美观，更方便绘制统计图表\nPlotly: 交互式可视化库，可创建动态图表",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>金融数据获取与数据分析基础</span>"
    ]
  },
  {
    "objectID": "lab02_data.html#ai-辅助编程实践",
    "href": "lab02_data.html#ai-辅助编程实践",
    "title": "3  金融数据获取与数据分析基础",
    "section": "3.4 AI 辅助编程实践",
    "text": "3.4 AI 辅助编程实践\n\n3.4.1 代码生成与解释\n\nAI 代码生成工具: Cursor, GitHub Copilot 等\n代码生成: 使用 Ctrl+K (或 Cmd+K) 快捷键，根据自然语言描述或代码上下文，自动生成代码片段或完整函数。 例如，在注释中输入 “用 Tushare 获取贵州茅台 (600519.SH) 2023年至今的日线数据”，AI 可以自动生成相应的 Python 代码。\n代码解释: 使用 Ctrl+L (或 Cmd+L) 快捷键，AI 工具可以解释选定代码的功能和逻辑，帮助理解代码。 例如，选中一段复杂的 Pandas 股票数据处理代码，使用 Ctrl+L 可以快速了解代码的功能。\n\n\n\n3.4.2 代码优化与调试\n\nAI 代码优化: AI 工具可以分析代码，提供性能优化建议，例如：\n\n代码效率优化: 改进算法、减少循环、使用向量化运算 (例如：优化股票数据批量处理循环)。 可以使用 Ctrl+I (或 Cmd+I) 快捷键，请求 AI 检查代码并给出优化建议。\n代码可读性优化: 代码格式化、变量命名建议、代码重构建议。 Ctrl+I 同样可以用于代码可读性优化。\n\nAI 代码调试: AI 工具可以辅助代码调试，例如：\n\n错误检测: 静态代码分析，检测潜在错误 (例如：检查股票数据处理代码中是否存在数据类型错误)。 某些 AI 工具可以在编写代码时实时检测错误。\nBug 定位: 根据错误信息和代码上下文，帮助定位 Bug。 AI 可以分析错误堆栈信息，并结合代码逻辑，给出可能的 Bug 位置和修复建议。\n智能提示: 提供代码补全、参数提示、错误提示，减少编码错误。\n\n\n\n\n3.4.3 最佳实践案例\n\n案例 1: 生成基础数据分析代码\n\n场景: 需要生成一段完整的代码，用于获取茅台股票数据并进行基本分析。\n操作: 在代码编辑器中输入以下注释，然后按下 Ctrl+K: python     # 使用tushare获取贵州茅台(600519.SH)最近30天的日线数据     # 计算日收益率、5日均线、20日均线     # 使用matplotlib绘制K线图，并在图上显示均线\n预期生成代码:\nimport tushare as ts\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 初始化tushare\nts.set_token('你的token')\npro = ts.pro_api()\n\n# 获取数据\nend_date = pd.Timestamp.today().strftime('%Y%m%d')\nstart_date = (pd.Timestamp.today() - pd.Timedelta(days=30)).strftime('%Y%m%d')\ndf = pro.daily(ts_code='600519.SH', start_date=start_date, end_date=end_date)\ndf['trade_date'] = pd.to_datetime(df['trade_date'])\ndf = df.sort_values('trade_date')\n\n# 计算指标\ndf['daily_return'] = df['close'].pct_change()\ndf['MA5'] = df['close'].rolling(window=5).mean()\ndf['MA20'] = df['close'].rolling(window=20).mean()\n\n# 绘图\nplt.figure(figsize=(12, 6))\nplt.plot(df['trade_date'], df['close'], label='收盘价')\nplt.plot(df['trade_date'], df['MA5'], label='5日均线')\nplt.plot(df['trade_date'], df['MA20'], label='20日均线')\nplt.title('贵州茅台股价走势')\nplt.xlabel('日期')\nplt.ylabel('价格')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n案例 2: 生成技术分析代码\n\n场景: 通过解释MACD指标的计算原理，生成更复杂的技术分析代码。\n操作: 输入以下注释，然后按下 Ctrl+L: python     # 请解释MACD指标的计算原理，并生成一个完整的函数来计算茅台股票的MACD指标     # 需要包含：     # 1. MACD的计算（快线、慢线、柱状图）     # 2. 买卖信号判断     # 3. 结果可视化\n预期生成代码:\ndef analyze_macd(stock_data, short_window=12, long_window=26, signal_window=9):\n    \"\"\"\n    计算并可视化MACD指标\n    - DIF(MACD线): 快速EMA与慢速EMA的差\n    - DEA(信号线): DIF的移动平均\n    - MACD柱: DIF与DEA的差值\n    \"\"\"\n    # 计算MACD\n    exp1 = stock_data['close'].ewm(span=short_window, adjust=False).mean()\n    exp2 = stock_data['close'].ewm(span=long_window, adjust=False).mean()\n    stock_data['DIF'] = exp1 - exp2\n    stock_data['DEA'] = stock_data['DIF'].ewm(span=signal_window, adjust=False).mean()\n    stock_data['MACD'] = 2 * (stock_data['DIF'] - stock_data['DEA'])\n\n    # 生成买卖信号\n    stock_data['SIGNAL'] = 0\n    stock_data.loc[stock_data['DIF'] &gt; stock_data['DEA'], 'SIGNAL'] = 1\n    stock_data.loc[stock_data['DIF'] &lt; stock_data['DEA'], 'SIGNAL'] = -1\n\n    # 可视化\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n\n    # 绘制股价\n    ax1.plot(stock_data['trade_date'], stock_data['close'])\n    ax1.set_title('茅台股价与MACD信号')\n    ax1.grid(True)\n\n    # 绘制MACD\n    ax2.plot(stock_data['trade_date'], stock_data['DIF'], label='DIF')\n    ax2.plot(stock_data['trade_date'], stock_data['DEA'], label='DEA')\n    ax2.bar(stock_data['trade_date'], stock_data['MACD'], label='MACD柱')\n    ax2.grid(True)\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n    return stock_data\n\n# 调用函数\ndf = analyze_macd(df)\n\n案例 3: 生成性能优化代码\n\n场景: 优化股票数据分析代码，生成更高效的实现。\n操作: 输入以下注释和代码，然后按下 Ctrl+I:\n# 请优化以下计算波动率的代码，使用向量化操作提高性能\n# 需要：\n# 1. 使用pandas的向量化操作\n# 2. 添加并行计算支持\n# 3. 增加性能监控\n\ndef calculate_volatility(close_prices):\n    volatility = []\n    for i in range(len(close_prices)-20):\n        window = close_prices[i:i+20]\n        daily_returns = []\n        for j in range(1, len(window)):\n            daily_return = (window[j] - window[j-1]) / window[j-1]\n            daily_returns.append(daily_return)\n        vol = np.std(daily_returns) * np.sqrt(252)\n        volatility.append(vol)\n    return volatility\n预期生成代码:\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef calculate_volatility_optimized(close_prices):\n    \"\"\"\n    优化后的波动率计算函数\n    - 使用pandas的向量化操作\n    - 支持并行计算\n    - 包含性能监控\n    \"\"\"\n    start_time = time.time()\n\n    # 计算日收益率（向量化操作）\n    returns = pd.Series(close_prices).pct_change().dropna()\n\n    # 使用rolling计算滚动波动率\n    volatility = returns.rolling(window=20).std() * np.sqrt(252)\n\n    # 并行计算示例（处理多个股票时使用）\n    def parallel_volatility(stock_returns):\n        return stock_returns.rolling(window=20).std() * np.sqrt(252)\n\n    with ThreadPoolExecutor() as executor:\n        # 这里可以处理多个股票的数据\n        results = list(executor.map(parallel_volatility, [returns]))\n\n    end_time = time.time()\n    print(f\"计算耗时: {end_time - start_time:.4f} 秒\")\n\n    return volatility\n\n# 性能对比\nprices = df['close'].values\n\n# 测试原始版本\nstart = time.time()\nvol1 = calculate_volatility(prices)\nprint(f\"原始版本耗时: {time.time() - start:.4f} 秒\")\n\n# 测试优化版本\nstart = time.time()\nvol2 = calculate_volatility_optimized(prices)\nprint(f\"优化版本耗时: {time.time() - start:.4f} 秒\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>金融数据获取与数据分析基础</span>"
    ]
  },
  {
    "objectID": "lab02_data.html#总结",
    "href": "lab02_data.html#总结",
    "title": "3  金融数据获取与数据分析基础",
    "section": "3.5 总结",
    "text": "3.5 总结\n\n数据是机器学习的基石：高质量的数据是构建有效模型的关键。\n金融数据获取多样化：掌握不同数据源和API接口，灵活获取所需数据，包括股票、债券、期货、财务报表和金融文本数据。\nPython 数据分析是必备技能：熟练运用 NumPy 和 Pandas 进行金融数据处理和分析。\nEDA 帮助理解数据：通过探索性数据分析，发现金融数据规律，为建模提供方向。\nAI 辅助编程提升效率：善用 AI 工具，提高金融数据获取和分析效率。 熟练使用AI工具，可以显著提升开发效率。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>金融数据获取与数据分析基础</span>"
    ]
  },
  {
    "objectID": "03_supervised.html",
    "href": "03_supervised.html",
    "title": "4  监督学习（上）",
    "section": "",
    "text": "4.1 监督学习简介\n监督学习是机器学习的一个重要分支，它是指从带有标签的数据中自动学习规律和模式，并利用这些规律和模式对新数据进行预测和决策的过程。在监督学习中，我们拥有一个包含输入特征 \\(\\mathbf{x}\\) 和对应输出标签 \\(y\\) 的数据集，模型的目标是学习一个从输入特征到输出标签的映射关系。监督学习在量化投资、金融科技等领域有广泛应用，例如：\n由于课程时间有限，本讲义将重点介绍监督学习中的回归、分类和集成学习，以及它们在金融预测中的应用。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>监督学习（上）</span>"
    ]
  },
  {
    "objectID": "03_supervised.html#监督学习简介",
    "href": "03_supervised.html#监督学习简介",
    "title": "4  监督学习（上）",
    "section": "",
    "text": "风险评估：根据客户的历史信用数据（特征）预测其信用风险等级（标签）。\n欺诈检测：基于交易记录（特征）识别欺诈交易（标签）。\n量化交易：预测股票价格走势（标签）以辅助交易决策（特征）。\n客户细分：根据客户特征（特征）预测客户所属类别（标签），进行精准营销。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>监督学习（上）</span>"
    ]
  },
  {
    "objectID": "03_supervised.html#监督学习模型详解",
    "href": "03_supervised.html#监督学习模型详解",
    "title": "4  监督学习（上）",
    "section": "4.2 监督学习模型详解",
    "text": "4.2 监督学习模型详解\n\n4.2.1 回归问题描述\n回归问题旨在通过由 \\(K \\times 1\\) 维向量 \\(\\mathbf{x}\\) 表示的 \\(K\\) 个观测到的预测变量（特征）来预测连续数值型的结果 \\(y\\)。 给定训练数据 \\(\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{N}\\)，其中 \\(\\mathbf{x}_i\\) 是第 \\(i\\) 个样本的特征向量， \\(y_i\\) 是对应的真实值， \\(N\\) 是样本数量。我们的目标是找到一个函数 \\(f\\)，使得对于新的输入 \\(\\mathbf{x}\\)，模型预测值 \\(\\hat{y} = f(\\mathbf{x})\\) 尽可能接近真实值 \\(y\\)。假设真实值 \\(y_i\\) 与预测函数 \\(f(\\mathbf{x}_i)\\) 之间存在如下关系：\n\\[y_i = f(\\mathbf{x}_i) + \\epsilon_i\\]\n其中 \\(\\epsilon_i\\) 代表随机误差项，通常假设其服从均值为 0 的正态分布。在实际应用中，我们通常将观测值堆叠成矩阵和向量的形式，方便模型表达和计算：\n\n\\(N \\times 1\\) 维结果向量 \\(\\mathbf{y} = (y_1, y_2, ..., y_N)^T\\)\n\\(N \\times K\\) 维特征矩阵 \\(\\mathbf{X} = (\\mathbf{x}_1, \\mathbf{x}_2, ..., \\mathbf{x}_N)^T\\)，每一行代表一个样本，每一列代表一个特征。\n\\(N \\times 1\\) 维误差向量 \\(\\mathbf{\\epsilon} = (\\epsilon_1, \\epsilon_2, ..., \\epsilon_N)^T\\)\n\n回归模型可以简洁地写为： \\(\\mathbf{y} = f(\\mathbf{X}) + \\mathbf{\\epsilon}\\)。我们的目标是通过训练数据学习到函数 \\(f\\) 的具体形式，从而能够对新的样本 \\(\\mathbf{x}\\) 进行预测。\n\n\n4.2.2 线性回归 (Linear Regression)\n线性回归模型是最简单且应用广泛的回归模型。它假设结果变量 \\(y\\) 与特征向量 \\(\\mathbf{x}\\) 之间存在线性关系。线性回归模型易于理解和实现，是许多复杂模型的基础。\n模型表达式:\n线性回归模型假设预测函数 \\(f(\\mathbf{x})\\) 是特征 \\(\\mathbf{x}\\) 的线性组合，模型表达式如下：\n\\(y = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{\\epsilon}\\)\n或者对于单个样本 \\(i\\)，可以表示为：\n\\(y_i = \\mathbf{x}_i^T \\mathbf{\\beta} + \\epsilon_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + ... + \\beta_K x_{iK} + \\epsilon_i\\)\n其中： - \\(\\mathbf{\\beta} = (\\beta_0, \\beta_1, ..., \\beta_K)^T\\) 是 \\((K+1) \\times 1\\) 维回归系数向量，\\(\\beta_0\\) 是截距项（bias），\\(\\beta_1, ..., \\beta_K\\) 是特征的系数。为了方便表示，我们通常在特征矩阵 \\(\\mathbf{X}\\) 中添加一列全为 1 的列向量，对应于截距项 \\(\\beta_0\\)。 - \\(\\mathbf{x}_i = (1, x_{i1}, x_{i2}, ..., x_{iK})^T\\) 是 \\((K+1) \\times 1\\) 维增广特征向量，包含了常数项 1 和原始特征。 - \\(\\epsilon_i\\) 是误差项。\n最优化方法：最小二乘法 (OLS)\n线性回归的目标是找到最优的回归系数 \\(\\mathbf{\\beta}\\)，使得模型的预测值 \\(\\mathbf{X}\\mathbf{\\beta}\\) 与真实值 \\(\\mathbf{y}\\) 之间的误差平方和 (Sum of Squared Errors, SSE) 最小。最小二乘法 (Ordinary Least Squares, OLS) 是一种常用的求解线性回归模型参数的方法。其目标函数为：\n\\[\\min_{\\mathbf{\\beta}} L(\\mathbf{\\beta}) = \\min_{\\mathbf{\\beta}} (\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta}) = \\min_{\\mathbf{\\beta}} \\sum_{i=1}^{N} (y_i - \\mathbf{x}_i^T \\mathbf{\\beta})^2\\]\n为了求解最优的 \\(\\mathbf{\\beta}\\)，我们可以对目标函数 \\(L(\\mathbf{\\beta})\\) 关于 \\(\\mathbf{\\beta}\\) 求导，并令导数等于 0，得到正规方程 (Normal Equation)：\n\\[\\mathbf{X}^T\\mathbf{X}\\mathbf{\\beta} = \\mathbf{X}^T\\mathbf{y}\\]\n如果矩阵 \\(\\mathbf{X}^T\\mathbf{X}\\) 可逆（即满秩），则可以得到普通最小二乘 (OLS) 估计量的解析解：\n\\[\\hat{\\mathbf{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T\\mathbf{y}\\]\n高维环境下的过拟合问题与正则化:\n在高维环境中，当特征数量 \\(K\\) 相对于观测数量 \\(N\\) 来说较大时（例如 \\(K &gt; N\\)，或 \\(K\\) 接近 \\(N\\)），OLS 估计可能会出现过拟合 (Overfitting) 问题。过拟合是指模型在训练集上表现得非常好（例如，训练误差很小），但在未见过的测试集上泛化能力很差，预测性能下降。这是因为在高维情况下，模型参数过多，容易捕捉到训练数据中的噪声和随机波动，而不是真实的 underlying pattern。\n为了解决过拟合问题，提高模型的泛化能力，可以引入正则化 (Regularization) 方法。正则化通过在损失函数中添加惩罚项，限制模型复杂度，从而避免模型过度拟合训练数据。常用的正则化方法包括 岭回归 (Ridge Regression) 和 Lasso 回归 (Lasso Regression)。\n\n\n4.2.3 岭回归 (Ridge Regression)\n岭回归是一种改进的线性回归方法，也称为 \\(L_2\\) 正则化线性回归。它通过在最小二乘法的损失函数中添加 \\(L_2\\) 范数惩罚项来对回归系数进行 shrinkage (收缩)，限制回归系数的大小，从而降低模型的复杂度和过拟合风险。岭回归特别适用于处理多重共线性问题，即特征之间存在高度相关性的情况。\n模型表达式:\n岭回归的目标函数为：\n\\[\\min_{\\mathbf{\\beta}} L_{Ridge}(\\mathbf{\\beta}) = \\min_{\\mathbf{\\beta}} \\left[ \\frac{1}{N} (\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta}) + \\lambda \\mathbf{\\beta}^T\\mathbf{\\beta} \\right] \\]\n其中： - \\(\\frac{1}{N} (\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})\\) 是均方误差 (Mean Squared Error, MSE) 项，衡量模型预测值与真实值之间的平均误差平方。 - \\(\\lambda \\mathbf{\\beta}^T\\mathbf{\\beta} = \\lambda ||\\mathbf{\\beta}||_2^2 = \\lambda \\sum_{j=0}^{K} \\beta_j^2\\) 是 \\(L_2\\) 范数惩罚项，也称为 权重衰减项 (Weight Decay)。它惩罚回归系数 \\(\\mathbf{\\beta}\\) 的平方和，迫使系数趋向于较小的值。 - \\(\\lambda \\ge 0\\) 是正则化参数 (Regularization Parameter)，也称为 惩罚系数。它控制惩罚项的强度。\\(\\lambda\\) 越大，惩罚越强，回归系数越趋向于 0。当 \\(\\lambda = 0\\) 时，岭回归退化为普通线性回归。\n估计方法:\n类似于线性回归，我们可以对岭回归的目标函数 \\(L_{Ridge}(\\mathbf{\\beta})\\) 关于 \\(\\mathbf{\\beta}\\) 求导，并令导数等于 0，得到岭回归的估计结果：\n\\[\\hat{\\mathbf{\\beta}}_{Ridge} = (\\mathbf{X}^T\\mathbf{X} + \\lambda \\mathbf{I}_{K+1})^{-1} \\mathbf{X}^T\\mathbf{y}\\]\n其中 \\(\\mathbf{I}_{K+1}\\) 是 \\((K+1) \\times (K+1)\\) 单位矩阵。通过向 \\(\\mathbf{X}^T\\mathbf{X}\\) 添加对角矩阵 \\(\\lambda \\mathbf{I}_{K+1}\\)（即”岭”），可以使得在求逆运算时，即使 \\(\\mathbf{X}^T\\mathbf{X}\\) 接近奇异矩阵（例如，当存在多重共线性时），\\((\\mathbf{X}^T\\mathbf{X} + \\lambda \\mathbf{I}_{K+1})\\) 仍然具有较好的可逆性，保证了解的稳定性。并且 \\(\\lambda \\mathbf{I}_{K+1}\\) 的存在将导致回归系数 \\(\\hat{\\mathbf{\\beta}}_{Ridge}\\) 向零收缩。\n岭回归的特点:\n\n\\(L_2\\) 正则化：使用 \\(L_2\\) 范数惩罚项，将回归系数向零收缩，但不会精确地变为 0。\n缓解多重共线性：通过引入正则化项，降低了模型对特征之间相关性的敏感度，可以缓解多重共线性问题，提高模型稳定性。\n降低过拟合风险：通过限制模型复杂度，有效降低过拟合风险，提高模型的泛化能力。\n无法进行特征选择：岭回归会缩小所有特征的系数，但不会将任何系数精确地设置为 0，因此无法进行特征选择。\n\n\n\n4.2.4 Lasso 回归 (Lasso Regression)\nLasso (Least Absolute Shrinkage and Selection Operator) 回归是另一种常用的正则化线性回归方法，也称为 \\(L_1\\) 正则化线性回归。与岭回归不同，Lasso 回归使用 \\(L_1\\) 范数惩罚项进行正则化。 \\(L_1\\) 正则化不仅可以进行系数 shrinkage，更重要的是，它具有 特征选择 (Feature Selection) 的能力，可以将一些不重要特征的回归系数压缩为 精确的 0，从而得到 稀疏模型 (Sparse Model)。稀疏模型更易于解释，并且可以提高模型的泛化能力。\n模型表达式:\nLasso 回归的目标函数为：\n\\[\\min_{\\mathbf{\\beta}} L_{Lasso}(\\mathbf{\\beta}) = \\min_{\\mathbf{\\beta}} \\left[ \\frac{1}{N} (\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta}) + \\gamma \\sum_{j=1}^{K} |\\beta_j| \\right]\\]\n其中： - \\(\\frac{1}{N} (\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})\\) 仍然是均方误差项。 - \\(\\gamma \\sum_{j=1}^{K} |\\beta_j| = \\gamma ||\\mathbf{\\beta}_{1:K}||_1 = \\gamma (|\\beta_1| + |\\beta_2| + ... + |\\beta_K|)\\) 是 \\(L_1\\) 范数惩罚项，注意这里只惩罚了特征系数 \\(\\beta_1, ..., \\beta_K\\)，不惩罚截距项 \\(\\beta_0\\)。 \\(L_1\\) 范数惩罚项迫使一些回归系数变为 0。 - \\(\\gamma \\ge 0\\) 是 正则化参数，控制 \\(L_1\\) 惩罚项的强度。\\(\\gamma\\) 越大，惩罚越强，更多的回归系数会被压缩为 0。\n估计方法:\n与岭回归不同，Lasso 回归的目标函数由于包含 \\(L_1\\) 范数项，在 \\(\\beta_j = 0\\) 处不可导，因此 没有解析解。通常需要使用数值优化算法（如坐标轴下降法 (Coordinate Descent)、近端梯度下降法 (Proximal Gradient Descent)）进行求解。\nLasso 回归的特点:\n\n\\(L_1\\) 正则化：使用 \\(L_1\\) 范数惩罚项，不仅可以进行系数 shrinkage，还可以将一些不重要特征的回归系数压缩为精确的 0，实现特征选择。\n稀疏模型：Lasso 回归可以产生稀疏模型，即模型中只有少数特征的系数非零，这有助于模型解释和提高泛化能力。\n特征选择能力：在特征选择方面优于岭回归。Lasso 回归可以自动选择重要的特征，去除冗余和不相关的特征。\n适用于高维稀疏数据：Lasso 回归特别适用于处理高维稀疏数据，例如文本数据、基因数据等。\n\n\n\n4.2.5 弹性网 (Elastic Net)\n弹性网 (Elastic Net) 是一种结合了岭回归和 Lasso 回归的正则化方法，可以看作是岭回归和 Lasso 回归的折衷。弹性网同时使用 \\(L_1\\) 范数和 \\(L_2\\) 范数惩罚项进行正则化。弹性网同时使用 \\(L_1\\) 正则化和 \\(L_2\\) 正则化，综合利用 \\(L_1\\) 正则化的特征选择能力和 \\(L_2\\) 正则化的稳定性和 shrinkage 能力。在某些情况下，弹性网的性能优于单独的岭回归和 Lasso 回归，尤其是在特征之间高度相关时，弹性网表现更稳定。\n模型表达式:\n弹性网的目标函数为：\n\\[\\min_{\\mathbf{\\beta}} L_{ElasticNet}(\\mathbf{\\beta}) = \\min_{\\mathbf{\\beta}} \\left[ \\frac{1}{N} (\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta}) + \\gamma_1 \\sum_{j=1}^{K} |\\beta_j| + \\gamma_2 \\mathbf{\\beta}^T\\mathbf{\\beta} \\right]\\]\n其中： - \\(\\frac{1}{N} (\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})\\) 是均方误差项。 - \\(\\gamma_1 \\sum_{j=1}^{K} |\\beta_j|\\) 是 \\(L_1\\) 范数惩罚项，用于特征选择和产生稀疏模型。 - \\(\\gamma_2 \\mathbf{\\beta}^T\\mathbf{\\beta}\\) 是 \\(L_2\\) 范数惩罚项，用于系数 shrinkage 和缓解多重共线性。 - \\(\\gamma_1 \\ge 0\\) 和 \\(\\gamma_2 \\ge 0\\) 分别是 \\(L_1\\) 正则化参数 和 \\(L_2\\) 正则化参数，控制两种惩罚项的强度。通常需要通过交叉验证等方法来选择合适的 \\(\\gamma_1\\) 和 \\(\\gamma_2\\) 值。\n弹性网的特点:\n\n结合 \\(L_1\\) 和 \\(L_2\\) 正则化：弹性网同时使用 \\(L_1\\) 和 \\(L_2\\) 范数惩罚项，结合了两者的优点。\n既可以进行特征选择，又可以进行系数 shrinkage：弹性网既可以像 Lasso 回归一样进行特征选择，将一些不重要特征的系数压缩为 0，又可以像岭回归一样进行系数 shrinkage，缩小系数的整体大小，提高模型稳定性。\n性能更稳定：在某些情况下，弹性网的预测性能和鲁棒性优于岭回归和 Lasso 回归。\n处理特征高度相关性：当特征之间高度相关时，Lasso 回归可能随机选择其中一个特征，而弹性网倾向于选择一组相关的特征，表现更稳定。\n\n\n\n4.2.6 分类问题描述\n分类问题旨在通过由 \\(K \\times 1\\) 维向量 \\(\\mathbf{x}\\) 表示的 \\(K\\) 个观测到的预测变量（特征）来预测离散类别型的结果 \\(y\\)。分类问题的目标是学习一个模型，将输入样本 \\(\\mathbf{x}\\) 划分到预定义的类别中。根据类别数量的不同，分类问题可以分为：\n\n二分类 (Binary Classification)：预测结果 \\(y\\) 只有两个类别，通常表示为 \\(y \\in \\{0, 1\\}\\) (或 \\(y \\in \\{-1, +1\\}\\))。例如，判断邮件是否为垃圾邮件（是/否），预测用户是否会点击广告（点击/不点击），识别交易是否为欺诈交易（欺诈/正常）。\n多分类 (Multiclass Classification)：预测结果 \\(y\\) 有两个以上的类别，表示为 \\(y \\in \\{C_1, C_2, ..., C_L\\}\\)，其中 \\(C_i\\) 是类别标签， \\(L \\ge 3\\) 是类别数量。例如，图像分类（猫、狗、鸟、鱼等），文本分类（政治、经济、体育、娱乐等），客户类型分类（高价值客户、中价值客户、低价值客户）。\n\n对于多分类问题，常用的处理策略是 “拆解法” (Decomposition)，即将多分类任务拆解为若干个二分类任务求解。常见的拆解策略包括 一对一 (One-vs-One, OvO)、一对多 (One-vs-Rest, OvR) 和 多对多 (Many-vs-Many, MvM) 等。\n\n\n4.2.7 类别不平衡问题\n在分类任务中，经常会遇到不同类别的训练样本数量差别很大的情况，即 类别不平衡 (Class Imbalance) 问题。例如，在欺诈检测、罕见病诊断、自然灾害预测等领域，少数类样本 (Minority Class)（如欺诈交易、患病样本、地震）的数量通常远远少于多数类样本 (Majority Class)（如正常交易、健康样本、非地震）。类别不平衡问题会严重影响模型的学习效果，使得模型更倾向于预测样本数量较多的类别，而对少数类别的识别率很低。\n类别不平衡的影响:\n\n模型偏向多数类：模型在训练过程中更容易学习到多数类样本的特征，而忽略少数类样本的特征，导致模型预测结果偏向多数类。\n整体分类精度虚高：由于多数类样本数量占优，即使模型将所有样本都预测为多数类，也可能获得较高的整体分类精度 (Accuracy)。但这种高精度是没有意义的，因为模型对少数类的识别能力很差。\n评估指标失效：常用的评估指标（如准确率 Accuracy）在类别不平衡数据集上可能失效，无法真实反映模型的性能。我们需要使用更合适的评估指标，例如 精确率 (Precision)、召回率 (Recall)、F1 值 (F1-score)、AUC 值 (Area Under ROC Curve) 等。\n\n类别不平衡的解决方案:\n为了解决类别不平衡问题，提高模型对少数类别的识别能力，常用的解决方案包括：\n\n再缩放 (Rescaling) / 阈值调整 (Threshold Adjustment)：不改变原始模型，而是调整分类阈值 (Classification Threshold)，使得模型在类别不平衡时也能做出合理的预测。例如，对于逻辑回归或 SVM 等输出概率的模型，默认的分类阈值通常为 0.5。当类别不平衡时，可以将预测为正例的阈值从 0.5 调整为更小的值，例如 \\(\\frac{m^{+}}{m^{-} + m^{+}}\\), 其中 \\(m^{+}\\) 和 \\(m^{-}\\) 分别是正类（少数类）和负类（多数类）样本的数量。降低阈值会使得模型更容易将样本预测为正类，从而提高少数类的召回率。\n重采样 (Resampling)：通过改变训练集中不同类别样本的比例来缓解类别不平衡问题。重采样方法包括 欠抽样 (Undersampling) 和 过抽样 (Oversampling)。\n\n欠抽样 (Undersampling)：减少多数类样本的数量，随机删除一部分多数类样本，使得正负类样本数量接近平衡。欠抽样方法简单易行，但可能会丢失一部分多数类样本的信息，适用于数据量较大的情况。\n过抽样 (Oversampling)：增加少数类样本的数量，例如通过复制少数类样本或生成合成样本（如 SMOTE (Synthetic Minority Over-sampling Technique)）。过抽样方法可以保留所有原始多数类样本的信息，但可能会导致过拟合，适用于数据量较小的情况。SMOTE 算法通过在少数类样本之间进行插值生成新的合成样本，可以有效缓解过拟合问题。\n\n阈值移动 (Threshold-moving)：这是一种代价敏感学习 (Cost-sensitive learning) 的思想。基于原始训练集进行学习，但在用训练好的分类器进行预测时，根据类别不平衡的程度调整决策阈值。例如，如果少数类样本的误分类代价更高，则可以将决策阈值向多数类方向移动，使得模型更倾向于将样本预测为少数类。\n代价敏感学习 (Cost-sensitive learning)：为不同类别的误分类设置不同的代价 (Cost)，使得模型在训练时更加关注少数类样本，最小化总的期望代价而不是最小化分类错误率。例如，可以使用代价矩阵 (Cost Matrix) 来定义不同误分类情况的代价，然后在训练过程中根据代价矩阵调整模型的学习策略。\n集成学习方法：一些集成学习方法，如 集成学习 (Ensemble Learning) 方法，例如 EasyEnsemble、BalanceCascade 等，通过将数据集划分为多个子集，在每个子集上训练基学习器，然后集成多个基学习器的预测结果，可以有效提高模型在类别不平衡数据集上的性能。\n\n\n\n4.2.8 逻辑回归 (Logistic Regression)\n逻辑回归 (Logistic Regression) 是一种广泛使用的二分类模型。虽然名字带有”回归”，但逻辑回归实际上是一种分类算法，主要用于解决二分类问题。逻辑回归模型简单高效，易于解释，是许多分类问题的 baseline 模型。\n模型表达式:\n逻辑回归模型基于线性回归的思想，但通过引入 Sigmoid 函数 (Sigmoid Function) 或 Logistic 函数，将线性回归的输出值映射到 \\((0, 1)\\) 区间，使其具有概率意义，用于表示样本属于正类的概率。\n逻辑回归模型的表达式如下：\n\\[P(y=1|\\mathbf{x}; \\mathbf{\\beta}) = \\sigma(\\mathbf{x}^T \\mathbf{\\beta}) = \\frac{1}{1 + e^{-\\mathbf{x}^T \\mathbf{\\beta}}}\\]\n其中： - \\(P(y=1|\\mathbf{x}; \\mathbf{\\beta})\\) 表示给定特征向量 \\(\\mathbf{x}\\) 和模型参数 \\(\\mathbf{\\beta}\\) 的条件下，样本属于正类 (y=1) 的概率。 - \\(\\mathbf{x} = (1, x_1, x_2, ..., x_K)^T\\) 是增广特征向量。 - \\(\\mathbf{\\beta} = (\\beta_0, \\beta_1, ..., \\beta_K)^T\\) 是模型参数，与线性回归中的回归系数类似。 - \\(\\sigma(z) = \\frac{1}{1 + e^{-z}}\\) 是 Sigmoid 函数，也称为 Logistic 函数。Sigmoid 函数将任意实数 \\(z\\) 映射到 \\((0, 1)\\) 区间，函数图像呈 S 形。当 \\(z \\rightarrow +\\infty\\) 时，\\(\\sigma(z) \\rightarrow 1\\)；当 \\(z \\rightarrow -\\infty\\) 时，\\(\\sigma(z) \\rightarrow 0\\)；当 \\(z = 0\\) 时，\\(\\sigma(z) = 0.5\\)。\n对于二分类问题，逻辑回归模型预测样本属于正类的概率 \\(P(y=1|\\mathbf{x}; \\mathbf{\\beta})\\)，则样本属于负类的概率为 \\(P(y=0|\\mathbf{x}; \\mathbf{\\beta}) = 1 - P(y=1|\\mathbf{x}; \\mathbf{\\beta}) = 1 - \\sigma(\\mathbf{x}^T \\mathbf{\\beta}) = \\sigma(-\\mathbf{x}^T \\mathbf{\\beta}) = \\frac{e^{-\\mathbf{x}^T \\mathbf{\\beta}}}{1 + e^{-\\mathbf{x}^T \\mathbf{\\beta}}} = \\frac{1}{1 + e^{\\mathbf{x}^T \\mathbf{\\beta}}}\\)。\n模型训练：最大似然估计 (Maximum Likelihood Estimation, MLE)\n逻辑回归模型的训练目标是最大化训练数据的似然函数 (Likelihood Function)，即找到一组模型参数 \\(\\mathbf{\\beta}\\)，使得在给定这组参数下，训练数据出现的概率最大。对于二分类问题，逻辑回归的似然函数可以表示为：\n\\[L(\\mathbf{\\beta}) = \\prod_{i=1}^{N} [P(y_i=1|\\mathbf{x}_i; \\mathbf{\\beta})]^{y_i} [P(y_i=0|\\mathbf{x}_i; \\mathbf{\\beta})]^{1-y_i} = \\prod_{i=1}^{N} [\\sigma(\\mathbf{x}_i^T \\mathbf{\\beta})]^{y_i} [\\sigma(-\\mathbf{x}_i^T \\mathbf{\\beta})]^{1-y_i}\\]\n为了方便优化，通常将似然函数取对数，得到对数似然函数 (Log-Likelihood Function)：\n\\[\\ell(\\mathbf{\\beta}) = \\ln L(\\mathbf{\\beta}) = \\sum_{i=1}^{N} [y_i \\ln \\sigma(\\mathbf{x}_i^T \\mathbf{\\beta}) + (1-y_i) \\ln \\sigma(-\\mathbf{x}_i^T \\mathbf{\\beta})] = \\sum_{i=1}^{N} [y_i \\ln \\frac{1}{1 + e^{-\\mathbf{x}_i^T \\mathbf{\\beta}}} + (1-y_i) \\ln \\frac{e^{-\\mathbf{x}_i^T \\mathbf{\\beta}}}{1 + e^{-\\mathbf{x}_i^T \\mathbf{\\beta}}}]\\]\n我们的目标是最大化对数似然函数 \\(\\ell(\\mathbf{\\beta})\\)，等价于最小化负对数似然函数 (Negative Log-Likelihood Function)：\n\\[J(\\mathbf{\\beta}) = -\\ell(\\mathbf{\\beta}) = - \\sum_{i=1}^{N} [y_i \\ln \\sigma(\\mathbf{x}_i^T \\mathbf{\\beta}) + (1-y_i) \\ln \\sigma(-\\mathbf{x}_i^T \\mathbf{\\beta})]\\]\n负对数似然函数 \\(J(\\mathbf{\\beta})\\) 也称为 交叉熵损失函数 (Cross-Entropy Loss Function) 或 Logistic Loss Function。\n最优化方法：梯度下降法 (Gradient Descent)\n逻辑回归模型通常使用梯度下降法 (Gradient Descent) 或其变种（如 随机梯度下降 (SGD)、小批量梯度下降 (Mini-batch GD)、Adam 等）来求解最优参数 \\(\\mathbf{\\beta}\\)，最小化交叉熵损失函数 \\(J(\\mathbf{\\beta})\\)。梯度下降法是一种迭代优化算法，通过不断沿着损失函数梯度 负方向 更新参数，逐步逼近最优解。\n决策边界 (Decision Boundary):\n逻辑回归模型的决策边界是线性的。当 \\(\\mathbf{x}^T \\mathbf{\\beta} = 0\\) 时，\\(\\sigma(\\mathbf{x}^T \\mathbf{\\beta}) = 0.5\\)，模型预测样本属于正类和负类的概率均为 0.5。因此，线性方程 \\(\\mathbf{x}^T \\mathbf{\\beta} = 0\\) 定义了逻辑回归模型的决策边界，将特征空间划分为正类区域和负类区域。\n\n\n4.2.9 支持向量机 (Support Vector Machine, SVM)\n支持向量机 (Support Vector Machine, SVM) 是一种强大且广泛应用于分类和回归问题的监督学习模型。SVM 的核心思想是找到一个最优超平面 (Optimal Hyperplane)，将不同类别的样本最大程度地分开，同时使得分类间隔 (Margin) 最大化。SVM 在高维空间和非线性分类问题中表现出色，通过核技巧 (Kernel Trick) 可以有效地处理非线性可分数据。\n线性可分支持向量机 (Linearly Separable SVM) / 硬间隔 SVM (Hard Margin SVM):\n对于线性可分 (Linearly Separable) 的数据集，即存在一个超平面可以将不同类别的样本完全分开的情况，我们可以构建线性可分支持向量机，也称为 硬间隔 SVM。硬间隔 SVM 旨在找到一个最大间隔超平面，将两类样本完全正确地分开，并且使得间隔最大化。间隔是指超平面到最近的样本点（称为 支持向量 (Support Vector)）的距离。\n模型表达式:\n给定线性可分的训练数据集 \\(D = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{N}\\)，其中 \\(y_i \\in \\{-1, +1\\}\\)。线性可分 SVM 的目标是找到一个超平面 \\((\\mathbf{w}, b)\\)，使得：\n\n正确分类: 所有样本都被正确分类，即对于 \\(y_i = +1\\) 的样本，有 \\(\\mathbf{w}^T \\mathbf{x}_i + b \\ge +1\\)；对于 \\(y_i = -1\\) 的样本，有 \\(\\mathbf{w}^T \\mathbf{x}_i + b \\le -1\\)。可以将两个不等式统一为： \\(y_i (\\mathbf{w}^T \\mathbf{x}_i + b) \\ge 1, \\quad i = 1, 2, ..., N\\)。\n间隔最大化: 最大化分类间隔 \\(Margin = \\frac{2}{||\\mathbf{w}||}\\)，等价于最小化 \\(||\\mathbf{w}||^2 = \\mathbf{w}^T \\mathbf{w}\\)。\n\n因此，线性可分 SVM 的最优化问题可以表示为：\n\\[\\min_{\\mathbf{w}, b} \\frac{1}{2} ||\\mathbf{w}||^2 \\quad \\text{s.t.} \\quad y_i (\\mathbf{w}^T \\mathbf{x}_i + b) \\ge 1, \\quad i = 1, 2, ..., N\\]\n这是一个凸二次规划 (Convex Quadratic Programming, QP) 问题，可以使用现成的 QP 求解器求解。\n线性不可分支持向量机 (Linearly Inseparable SVM) / 软间隔 SVM (Soft Margin SVM):\n在实际应用中，很多数据集不是线性可分的，即不存在一个超平面可以将不同类别的样本完全分开。为了处理线性不可分数据，我们需要引入软间隔 SVM，也称为 线性支持向量机。软间隔 SVM 允许模型在一些样本上分类错误，但希望尽可能减少分类错误，同时保持间隔最大化。\n模型表达式:\n软间隔 SVM 通过引入松弛变量 (Slack Variables) \\(\\xi_i \\ge 0\\)，允许一些样本不满足硬间隔约束 \\(y_i (\\mathbf{w}^T \\mathbf{x}_i + b) \\ge 1\\)。松弛变量 \\(\\xi_i\\) 表示第 \\(i\\) 个样本违反约束的程度。软间隔 SVM 的最优化问题变为：\n\\[\\min_{\\mathbf{w}, b, \\xi} \\frac{1}{2} ||\\mathbf{w}||^2 + C \\sum_{i=1}^{N} \\xi_i \\quad \\text{s.t.} \\quad y_i (\\mathbf{w}^T \\mathbf{x}_i + b) \\ge 1 - \\xi_i, \\quad \\xi_i \\ge 0, \\quad i = 1, 2, ..., N\\]\n其中： - \\(\\frac{1}{2} ||\\mathbf{w}||^2\\) 仍然是间隔最大化项。 - \\(C \\sum_{i=1}^{N} \\xi_i\\) 是惩罚项，表示对误分类的惩罚。 \\(\\xi_i\\) 越大，误分类程度越高，惩罚越大。 - \\(C &gt; 0\\) 是 惩罚参数 (Penalty Parameter)，也称为 正则化参数。 \\(C\\) 控制对误分类的惩罚程度。 \\(C\\) 越大，对误分类的惩罚越大，模型越倾向于减小误分类，但可能会导致间隔变小，容易过拟合； \\(C\\) 越小，对误分类的惩罚越小，模型更容忍误分类，间隔可能更大，泛化能力可能更好。 \\(C\\) 的选择需要通过交叉验证等方法进行调优。\n核函数 (Kernel Function):\n对于非线性可分 (Nonlinearly Separable) 的数据集，SVM 可以通过 核函数 (Kernel Function) 将数据映射到高维空间 (High-Dimensional Space)，使得在高维空间中数据变得线性可分，然后在高维空间中寻找最优超平面。核技巧 (Kernel Trick) 的强大之处在于，我们不需要显式地计算高维空间的特征向量，只需要定义一个核函数 \\(K(\\mathbf{x}_i, \\mathbf{x}_j)\\)，它可以计算原始空间中两个向量 \\(\\mathbf{x}_i\\) 和 \\(\\mathbf{x}_j\\) 映射到高维空间后的内积。常用的核函数包括：\n\n线性核 (Linear Kernel): \\(K(\\mathbf{x}_i, \\mathbf{x}_j) = \\mathbf{x}_i^T \\mathbf{x}_j\\)。线性核实际上没有进行特征映射，适用于线性可分数据。\n多项式核 (Polynomial Kernel): \\(K(\\mathbf{x}_i, \\mathbf{x}_j) = (\\gamma \\mathbf{x}_i^T \\mathbf{x}_j + r)^d\\)。多项式核可以将数据映射到多项式特征空间，适用于多项式关系的数据。其中 \\(\\gamma &gt; 0, r \\ge 0, d \\ge 1\\) 是核参数。\n高斯核 / RBF 核 (Gaussian Kernel / Radial Basis Function Kernel): \\(K(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp(-\\gamma ||\\mathbf{x}_i - \\mathbf{x}_j||^2)\\)。高斯核是最常用的核函数之一，可以将数据映射到无限维空间，适用于各种类型的数据，尤其是局部性模式的数据。其中 \\(\\gamma &gt; 0\\) 是核参数，控制核函数的宽度。\nSigmoid 核 (Sigmoid Kernel): \\(K(\\mathbf{x}_i, \\mathbf{x}_j) = \\tanh(\\gamma \\mathbf{x}_i^T \\mathbf{x}_j + r)\\)。Sigmoid 核类似于神经网络中的 Sigmoid 激活函数，SVM 使用 Sigmoid 核时，其行为类似于多层感知机神经网络。其中 \\(\\gamma &gt; 0, r &lt; 0\\) 是核参数。\n\n最优化方法：对偶问题与 SMO 算法\nSVM 的优化问题（无论是硬间隔还是软间隔）通常转化为 对偶问题 (Dual Problem) 进行求解。求解对偶问题的好处包括： 1. 更容易求解：对偶问题通常比原始问题更容易求解。 2. 引入核函数：在对偶问题中，目标函数和约束条件只涉及到样本之间的内积，可以方便地引入核函数，将线性 SVM 扩展到非线性 SVM。\n求解 SVM 对偶问题的高效算法是 SMO (Sequential Minimal Optimization) 算法。SMO 算法是一种启发式算法，它将大规模 QP 问题分解为一系列小规模 QP 子问题，通过迭代地优化两个变量，高效地求解 SVM 模型。\n\n\n4.2.10 决策树 (Decision Tree)\n决策树 (Decision Tree) 是一种树形结构的分类或回归模型。决策树模型直观易懂，易于解释，并且可以处理类别型和数值型特征，无需进行特征缩放。决策树模型的核心思想是基于特征对数据集进行递归划分，构建一棵树状的决策规则，用于对新样本进行分类或预测。\n决策树由节点 (Node) 和 有向边 (Directed Edge) 组成。节点分为两种类型： - 内部节点 (Internal Node)：表示一个特征或属性的测试条件，用于决定样本的划分方向。 - 叶节点 (Leaf Node / Terminal Node)：表示最终的决策结果，即类别标签（分类树）或预测值（回归树）。\n有向边代表划分规则，从父节点指向子节点。从根节点到每个叶节点的路径都对应着一条决策规则。\n决策树的学习过程主要包括三个步骤：特征选择、树的生成 和 树的剪枝。\n回归树 (Regression Tree):\n回归树 (Regression Tree) 用于预测连续数值型目标变量。例如，预测房价、股票价格等。\n模型构建:\n回归树的构建过程是一个递归的二叉树构建过程，也称为 CART (Classification and Regression Tree) 树。CART 树是一种二叉树，内部节点根据特征取值将数据集划分为两个子集，叶节点输出预测值。回归树的构建过程如下：\n\n选择划分特征和划分点：从所有特征和所有可能的划分点中，选择一个最优的特征 \\(j\\) 和切分点 \\(s\\)，将当前节点的数据集划分为两个区域 \\(R_1(j,s) = \\{\\mathbf{x}|\\mathbf{x}_j \\le s\\}\\) 和 \\(R_2(j,s) = \\{\\mathbf{x}|\\mathbf{x}_j &gt; s\\}\\)。\n最小化平方误差：选择最优划分属性 \\(j\\) 和划分点 \\(s\\) 的目标是最小化划分后的平方误差 (Squared Error)，即使得划分后的两个子区域内样本的目标变量值尽可能接近。对于给定的特征 \\(j\\) 和切分点 \\(s\\)，遍历所有可能的 \\((j, s)\\) 对，计算划分后的平方误差，选择使得平方误差最小的 \\((j, s)\\) 对作为最优划分。平方误差的计算公式为：\n\n\\[\\min_{j,s} \\left[ \\min_{c_1} \\sum_{\\mathbf{x}_i \\in R_1(j,s)} (y_i - c_1)^2 + \\min_{c_2} \\sum_{\\mathbf{x}_i \\in R_2(j,s)} (y_i - c_2)^2\\right]\\]\n其中 \\(c_1\\) 和 \\(c_2\\) 分别是区域 \\(R_1(j,s)\\) 和 \\(R_2(j,s)\\) 的预测值。对于给定的区域 \\(R_m(j,s)\\)，最优的预测值 \\(\\hat{c}_m\\) 是该区域内样本目标变量的均值：\n\\[\\hat{c}_m = \\text{ave}(y_i|\\mathbf{x}_i \\in R_m(j,s)) = \\frac{1}{|R_m(j,s)|} \\sum_{\\mathbf{x}_i \\in R_m(j,s)} y_i\\]\n\n递归划分：对划分后的两个子区域 \\(R_1(j,s)\\) 和 \\(R_2(j,s)\\)，递归地重复步骤 1 和 2，继续选择最优特征和切分点进行划分，直到满足停止条件。停止条件通常包括：\n\n节点内样本数量小于某个预设阈值。\n节点内样本的目标变量方差或平方误差小于某个阈值。\n没有更多特征可用于划分，或所有特征都已用完。\n\n生成叶节点：当满足停止条件时，将当前节点作为叶节点，并计算叶节点的预测值，通常为叶节点内样本目标变量的均值。\n\n分类树 (Classification Tree):\n分类树 (Classification Tree) 用于预测离散类别型目标变量。例如，判断用户是否会流失、识别图像中的物体类别等。\n模型构建:\n分类树的构建过程与回归树类似，也是一个递归的二叉树构建过程。不同之处在于，分类树在选择最优特征和切分点时，使用的划分指标不同，以及叶节点的预测值类型不同。分类树常用的划分指标包括 信息增益 (Information Gain)、信息增益率 (Information Gain Ratio) 和 基尼指数 (Gini Index)。目标是使得划分后的子节点数据尽可能 “纯净” (Pure)，即属于同一类别的样本比例尽可能高。\n划分指标:\n\n信息增益 (Information Gain)：基于信息熵 (Entropy) 的划分指标。信息熵衡量了数据集的混乱程度或不确定性。信息增益表示使用特征 \\(A\\) 对数据集 \\(D\\) 进行划分后，数据集 \\(D\\) 的信息熵减少的程度。信息增益越大，说明使用特征 \\(A\\) 划分数据集的效果越好。常用的基于信息增益的决策树算法是 ID3 算法。\n信息增益率 (Information Gain Ratio)：为了克服信息增益对取值数目较多的特征的偏好，C4.5 算法引入了信息增益率。信息增益率在信息增益的基础上，除以特征 \\(A\\) 本身的熵，对特征取值数目较多的情况进行惩罚。常用的基于信息增益率的决策树算法是 C4.5 算法。\n基尼指数 (Gini Index)：基尼指数衡量了数据集的纯度。基尼指数越小，数据集纯度越高。CART 算法使用基尼指数作为分类树的划分指标。\n\n叶节点预测值:\n分类树的叶节点输出类别标签，通常是叶节点内样本数量最多的类别（多数表决）。\n决策树的特点:\n\n优点：\n\n易于理解和解释：决策树模型直观易懂，决策规则清晰可见，易于向业务人员解释。\n可以处理类别型和数值型特征：无需对特征进行预处理，如独热编码、标准化等。\n无需特征缩放：决策树模型对特征的尺度不敏感，无需进行特征缩放。\n可以处理缺失值：决策树模型可以处理包含缺失值的数据。\n可以进行特征选择：决策树模型在构建过程中会自动选择重要的特征进行划分。\n\n缺点：\n\n容易过拟合：决策树模型容易在训练集上过拟合，导致泛化能力差。可以通过剪枝 (Pruning) 等方法缓解过拟合问题。\n不稳定：决策树模型对训练数据敏感，训练数据的微小变化可能导致树结构发生很大变化。\n忽略特征之间的相关性：决策树模型在选择划分特征时，每次只考虑一个特征，忽略了特征之间的相关性。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>监督学习（上）</span>"
    ]
  },
  {
    "objectID": "03_supervised.html#总结",
    "href": "03_supervised.html#总结",
    "title": "4  监督学习（上）",
    "section": "4.3 总结",
    "text": "4.3 总结\n本讲义主要介绍了监督学习的基本概念和常用模型，包括：\n\n监督学习概述: 介绍了监督学习的定义、应用场景以及与量化投资的结合。\n回归模型: 详细讲解了线性回归和岭回归模型，包括模型表达式、最小二乘法、正则化以及模型特点。\n分类模型: 深入探讨了支持向量机 (SVM) 和决策树模型，包括模型原理、核函数、优化方法以及模型优缺点。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>监督学习（上）</span>"
    ]
  },
  {
    "objectID": "project1_LC.html",
    "href": "project1_LC.html",
    "title": "5  借贷违约风险评估",
    "section": "",
    "text": "5.1 项目背景\nLending Club（NYSE：LC）创立于2006年，是一家在线撮合借款和出借的P2P平台，公司位于美国旧金山。公司上线运营初期仅提供个人贷款（personal loans）服务，后增加了医疗信贷（patient loans）、车贷分期（auto refinancing loans）。2014年12月12日开始在纽交所挂牌交易，成为当年最大的科技股IPO，2014年前后公司增加小微企业贷（small business loans）服务。该公司报告称，截至2015年12月31日，已通过其平台发放了159.8亿美元的贷款。\n借款人可以在LC平台上申请1,000美元到40,000美元之间的无担保个人贷款。标准贷款期限为三年。投资者可以在LC网站上搜索和浏览贷款清单，并根据提供的有关借款人、贷款金额、贷款等级和贷款目的的信息选择他们想要投资的贷款。投资者从这些贷款的利息中获利。\nLC负责贷款的审批和定价，贷款对应票据凭证的发行，以及贷后月度收款付款以及逾期后催收等服务。贷款的实际发放者是一家注册在犹他州的商业银行Web Bank。贷款产生的违约风险、提前还款和再投资风险，都由投资者自行承担。\nLC自行开发了风险评估和定价模型。公司会采用来自两个以上信用局的FICO评分（由美国Fair Isaac公司开发出的个人信用评级法），有时候借款人满足以上所有要求，他们也可能被拒绝。LC可能会要求验证借款人的其他信息。虽然LC的贷款审批只需7天-14天，但目前只有10%的贷款申请被批准，约90%的贷款申请被拒绝。\nLending Club的收入来源为交易手续费、服务费和管理费。交易手续费是向借款人收取的费用；服务费是向投资者收取的费用；管理费是管理投资基金和其他管理账户的费用。交易手续费是Lending Club收入的主要来源。\n尽管被视为金融科技行业的先驱和最大的此类公司之一，LC在2016年初遇到了问题，难以吸引投资者，公司的一些贷款丑闻以及董事会对首席执行官雷诺拉普朗什披露信息的担忧导致其股价大幅下跌和拉普朗什辞职。\n2020年，LC收购了Radius Bank，并宣布将关闭其P2P借贷平台。现有账户持有人将继续对现有票据收取利息，直到每笔贷款还清或违约，但没有新贷款可用于个人投资。也不再可能像以前那样通过二级市场出售现有贷款。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>借贷违约风险评估</span>"
    ]
  },
  {
    "objectID": "project1_LC.html#项目目标",
    "href": "project1_LC.html#项目目标",
    "title": "5  借贷违约风险评估",
    "section": "5.2 项目目标",
    "text": "5.2 项目目标\n本项目旨在利用Lending Club提供的历史贷款数据，构建机器学习模型以预测贷款是否会违约。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>借贷违约风险评估</span>"
    ]
  },
  {
    "objectID": "project1_LC.html#数据简介",
    "href": "project1_LC.html#数据简介",
    "title": "5  借贷违约风险评估",
    "section": "5.3 数据简介",
    "text": "5.3 数据简介\nLending Club贷款数据，覆盖2007.6-2018.12时间段，包含以下几类信息：\n\n贷款基本信息：\n\nid：贷款唯一标识符\nissue_d：贷款发布时间\nloan_amnt：贷款金额\nterm：贷款期限（36或60个月）\nint_rate：贷款利率\ninstallment：每月还款额\ngrade & sub_grade：LC给出的信用评级\nloan_status：贷款状态（是否违约）\npurpose：贷款目的\n\n借款人信息：\n\nemp_title：工作职位\nemp_length：工作年限\nannual_inc：年收入\ndti：债务收入比(DTI)\nhome_ownership：房产拥有状态\n\n信用数据：\n\nfico_range_low & fico_range_high：FICO分数范围\nopen_acc：开放信用账户数\nrevol_bal：循环信用余额\nrevol_util：循环额度利用率\n\n\n原始数据集包含145个变量和约200万条记录。本项目将使用其中的子集进行分析。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>借贷违约风险评估</span>"
    ]
  },
  {
    "objectID": "project1_LC.html#样本与变量选择",
    "href": "project1_LC.html#样本与变量选择",
    "title": "5  借贷违约风险评估",
    "section": "5.4 样本与变量选择",
    "text": "5.4 样本与变量选择\n\n时间范围：选择2013-2014年发放的、期限为3年的贷款数据。这些贷款在2018年底已全部结束，因此有完整的还款结果。\n特征选择原则：\n\n剔除所有贷后信息，因为这些信息在贷款发放时并不可得，包括：\n\n包含recover字段的变量（与回收相关）\n包含settlement字段的变量（与结算相关）\n包含pymnt字段的变量（与付款相关）\n以total_rec开始的变量（与收款总额相关）\n以out_prncp开始的变量（与未偿本金相关）\n\n只保留那些在贷款申请和审批过程中可获得的信息，以构建具有实际预测价值的模型",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>借贷违约风险评估</span>"
    ]
  },
  {
    "objectID": "project1_LC.html#项目步骤建议仅供参考",
    "href": "project1_LC.html#项目步骤建议仅供参考",
    "title": "5  借贷违约风险评估",
    "section": "5.5 项目步骤建议（仅供参考）",
    "text": "5.5 项目步骤建议（仅供参考）\n\n5.5.1 数据清理与特征工程\n\n数据探索分析：\n\n计算各变量的基本统计量（均值、中位数、标准差等）\n检测并处理缺失值、异常值和不合法值\n分析目标变量的分布情况，评估类别不平衡程度\n\n数据预处理：\n\n缺失值处理：根据变量类型选择适当的填补方法（均值、中位数、众数或特殊值）\n异常值处理：识别并处理离群点（可使用箱线图、Z-score等方法）\n特征变换：将分类变量转换为哑变量，对数值变量进行标准化或归一化\n\n特征工程：\n\n特征选择：去除低方差特征、高度相关特征或具有较多缺失值的特征\n特征创建：根据业务理解创建新的特征（如各类比率、差值等）\n特征重要性评估：使用统计方法或模型预测能力评估特征重要性\n\n数据可视化：\n\n绘制变量分布图，分析变量与目标的关系\n使用散点图、热力图等展示变量间相关性\n生成变量重要性图表\n\n\n\n\n5.5.2 数据建模与模型评估\n\n数据集划分：\n\n训练集（60%）：用于模型训练\n验证集（20%）：用于超参数调优\n测试集（20%）：用于最终模型评估，模拟真实应用场景\n\n处理类别不平衡：\n\n尝试欠抽样（减少多数类样本）或过抽样（增加少数类样本）技术\n考虑SMOTE等合成样本生成方法\n调整类别权重或使用集成学习方法\n\n模型构建与选择： 尝试以下几种分类模型并进行比较：\n\nLogistic回归：基准模型，易于解释\n决策树：能够捕捉非线性关系，提供决策规则\n随机森林：降低过拟合风险，提高预测稳定性\n梯度提升树（如XGBoost、LightGBM）：通常具有较高的预测准确率\n\n模型调优：\n\n使用网格搜索或随机搜索方法确定最优超参数\n利用交叉验证评估模型稳定性\n根据验证集表现选择最佳模型配置\n\n模型评估：\n\n计算多种评估指标：\n\n混淆矩阵：TP、TN、FP、FN\n精度（Accuracy）：整体分类正确率\n查准率（Precision）：预测为违约中实际违约的比例\n查全率（Recall）：实际违约中被成功预测的比例\nF1分数：Precision和Recall的调和平均\nROC曲线与AUC值：评估模型在不同阈值下的性能\nKS统计量：衡量模型区分好坏客户的能力\n\n分析模型的业务价值：计算不同决策阈值下的潜在收益和损失\n\n模型解释：\n\n分析特征重要性\n部分依赖图或SHAP值分析，理解特征对预测的影响\n提出基于模型的业务洞见和建议",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>借贷违约风险评估</span>"
    ]
  },
  {
    "objectID": "project1_LC.html#提交要求",
    "href": "project1_LC.html#提交要求",
    "title": "5  借贷违约风险评估",
    "section": "5.6 提交要求",
    "text": "5.6 提交要求\n\n展示Slides：\n\n简明扼要展示项目主要发现和结果\n说明对违约预测有显著影响的变量、特征工程、模型选择\n包含关键可视化图表\n演示时间控制在8分钟以内\n\n项目代码文件：\n\n提交完整的、有注释的Python代码（可以是多个Python文件）\n代码应包含从数据导入、清洗、特征工程到模型训练、评估的全过程\n确保代码可重复运行，并包含必要的环境依赖说明\n\n提交方式与截止日期：\n\n通过学习通平台提交所有文件\n项目展示Slides和项目代码打包为一个ZIP文件\n截止日期：2025年4月20日23:59",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>借贷违约风险评估</span>"
    ]
  }
]